# tflite_knn.py
# Implement KNN in Tensorflow and export it to TFLite.
# Source: https://ata-tech.medium.com/running-k-nearest-neighbors-on-
#   tensorflow-lite-e3affba4d706
# Python 3.7
# Windows/MacOS/Linux


import tempfile
from typing import List, Union

import numpy as np
import tensorflow as tf
from sklearn.datasets import make_blobs
from sklearn.model_selection import train_test_split


def main():
	# Constants.
	K = 3 # the number of neighbors found for each KNN search
	N_FEATURES = 2 # the number of features for input data
	N_SAMPLES = 1000 # the number of samples (dataset size)
	N_CENTERS = 5 # the number of clusters drawn from the synthetic data
	RANDOM_STATE = 0 # seed value for deterministic experiment
	TEST_SIZE = 0.3 # ratio of data size split for test set


	# Since KNN is a lazy algorithm where inference (the search
	# process) requires access to the enrolled data (training data),
	# there are a couple of points worth noting:
	# -> TfKNN needs to take in the training data (train_tensor) as an
	#	attribute in order to run the search operation at inference.
	# -> The distance function used in TfKNN is l2 distance.
	# -> TfKNN.neighbors is the function that performs KNN search. 
	#	Also, after TF lite conversation, this is the method executed
	#	by the tflite method.
	class TfKNN(tf.Module):
		def __init__(self, k: int, train_tensor: tf.Tensor):
			super().__init__()
			self.k = k
			self.train_tensor = train_tensor  # 2D tensor (n_samples, n_features)
			self.n_samples = self.train_tensor.shape[0]


		@staticmethod
		def l2_distance(tensor_1: tf.Tensor, tensor_2: tf.Tensor) -> tf.Tensor:
			return tf.norm(tensor_1 - tensor_2, ord="euclidean")


		@tf.function(
			input_signature=[tf.TensorSpec(shape=(N_FEATURES,), 
			dtype=tf.float32)]
		)
		def neighbors(self, tensor: tf.Tensor) -> tf.Tensor:
			"""Find the nearest neighbors' indices of a given tensor"""
			distances = tf.map_fn(
				fn=lambda t: self.l2_distance(tensor, t),
				elems=self.train_tensor,
				fn_output_signature=tf.TensorSpec((), dtype=tf.float32),
			)

			k = tf.math.minimum(self.k, self.n_samples)
			top_k_indices = tf.argsort(
				distances, axis=-1, direction="ASCENDING"
			)[:k]
			return top_k_indices


		def export_tflite(self, tflite_path: str):
			with tempfile.TemporaryDirectory() as tmpdir:
				# save model
				tf.saved_model.save(self, tmpdir)
				# convert the model
				converter = tf.lite.TFLiteConverter.from_saved_model(
					tmpdir
				)  # path to the SavedModel directory
				tflite_model = converter.convert()

				# save the model
				with open(tflite_path, "wb") as f:
					f.write(tflite_model)


	# TfliteKNN is a class which encapsulates the loading and running 
	# of tflite Interpreter. TfliteKNN.neighbors is functionally 
	# equivalent to TfKNN.neighbors (perform nearest neighbors search).
	class TfliteKNN:
		def __init__(self, tflite_path: str):
			self.tflite_path = tflite_path
			self._is_loaded = False

		def load(self):
			self.interpreter = tf.lite.Interpreter(self.tflite_path)
			self.input_details = self.interpreter.get_input_details()
			self.output_details = self.interpreter.get_output_details()

		def neighbors(self, tensor: List[float]) -> List[int]:
			if not self._is_loaded:
				self.load()

			input_index = self.input_details[0]["index"]
			input_data = np.array(tensor, dtype=np.float32)
			self.interpreter.allocate_tensors()
			self.interpreter.set_tensor(input_index, input_data)
			self.interpreter.invoke()

			output = self.interpreter.get_tensor(
				self.output_details[0]["index"]
			)
			return list(output)

	# Evaluation
	# Dataset: 
	# The dataset is generated by using make_blobs() function from
	# sklearn.datasets. The dataset size is 1000, and the test ratio is
	# 0.3.


	# Evaluation process:
	# Step 1: training data is enrolled into TfKNN
	# Step 2: tflite model is exported from TfKNN
	# Step 3: run knn search on both TfKNN and TfliteKNN
	# Step 4: compare search results on test data from both 
	#	implementations
	def knn_search(X_test: np.ndarray, knn: Union[TfliteKNN, TfKNN]) -> np.ndarray:
		nearest_neighbors = []
		for x in X_test:
			nearest_neighbors.append(knn.neighbors(x))
		return np.array(nearest_neighbors)


	# The following snippet runs the experiment and confirmed the 
	# results from tf_knnand tflite_knn are identical.
	dataset, center_labels, centers = make_blobs(
		n_samples=N_SAMPLES,
		n_features=N_FEATURES,
		centers=N_CENTERS,
		return_centers=True,
		random_state=RANDOM_STATE,
	)
	X_train, X_test, cluster_train, cluster_test = train_test_split(
		dataset, center_labels, test_size=TEST_SIZE, 
		random_state=RANDOM_STATE
	)

	train_tensor = tf.constant(
		X_train, dtype=tf.float32
	)  # shape = (n_train_samples, N_FEATURES)
	test_tensor = tf.constant(
		X_test, dtype=tf.float32
	)  # shape = (n_test_samples, N_FEATURES)

	tf_knn = TfKNN(k=K, train_tensor=train_tensor)

	# write to tflite
	tflite_path = "knn.tflite"
	tf_knn.export_tflite(tflite_path)

	tflite_knn = TfliteKNN(tflite_path)

	tf_knn_nn = knn_search(X_test, tf_knn)
	tf_lite_knn_nn = knn_search(X_test, tflite_knn)

	np.testing.assert_equal(tf_knn_nn, tf_lite_knn_nn)


	# Bonus: Using KNN for clustering
	# Besides the comparison evaluation, one additional experiment that
	# was done was to use KNN for clustering. Specifically, since 
	# make_blobs() provides an option to specify the number of clusters
	# to generate the data, we can utilize that for doing clustering.
	def evaluate(
		X_test: np.ndarray,
		cluster_train: np.ndarray,
		cluster_test: np.ndarray,
		knn: Union[TfliteKNN, TfKNN],
		) -> float:
			test_tensor = tf.constant(X_test, dtype=tf.float32)
			nearest_neighbors = []
			for sample in test_tensor:
				nn = knn.neighbors(sample)
			nearest_neighbors.append(nn)

			# convert from nearest samples to nearest clusters
			majority_vote = lambda arr: np.argmax(np.bincount(arr))
			nearest_clusters = []
			for nn in nearest_neighbors:
				clusters = [cluster_train[i] for i in nn]

			# majority vote
			nc = majority_vote(clusters)
			nearest_clusters.append(nc)

			accuracy = (
				np.sum(np.array(nearest_clusters) == np.array(cluster_test))
					/ cluster_test.shape[0]
			)
			return accuracy


	dataset, center_labels, centers = make_blobs(
		n_samples=N_SAMPLES,
		n_features=N_FEATURES,
		centers=N_CENTERS,
		return_centers=True,
		random_state=RANDOM_STATE,
	)
	X_train, X_test, cluster_train, cluster_test = train_test_split(
		dataset, center_labels, test_size=TEST_SIZE, 
		random_state=RANDOM_STATE
	)

	train_tensor = tf.constant(
		X_train, dtype=tf.float32
	)  # shape = (n_train_samples, N_FEATURES)
	test_tensor = tf.constant(
		X_test, dtype=tf.float32
	)  # shape = (n_test_samples, N_FEATURES)

	tf_knn = TfKNN(k=K, train_tensor=train_tensor)

	# write to tflite
	tflite_path = "knn.tflite"
	tf_knn.export_tflite(tflite_path)

	tflite_knn = TfliteKNN(tflite_path)

	tf_knn_acc = evaluate(
		X_test=X_test, cluster_train=cluster_train, 
		cluster_test=cluster_test, knn=tf_knn
	)
	tflite_knn_acc = evaluate(
		X_test=X_test,
		cluster_train=cluster_train,
		cluster_test=cluster_test,
		knn=tflite_knn,
	)

	print(f"Tf KNN accuracy:{tf_knn_acc}, TfLite KNN accuracy: {tflite_knn_acc}")

	# Exit the program.
	exit(0)


if __name__ == '__main__':
	main()